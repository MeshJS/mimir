# Logging Configuration
MIMIR_LOGGING_LEVEL=info
MIMIR_LOGGING_PRETTY=true

# Server Configuration
MIMIR_SERVER_API_KEY=change-me
MIMIR_SERVER_GITHUB_WEBHOOK_SECRET=your-shared-secret
MIMIR_SERVER_FALLBACK_INGEST_INTERVAL_MINUTES=60

# Supabase Configuration
MIMIR_SUPABASE_URL=https://your-project.supabase.co
MIMIR_SUPABASE_ANON_KEY=your_anon_key
MIMIR_SUPABASE_SERVICE_ROLE_KEY=your_service_role_key
MIMIR_SUPABASE_TABLE=documents
MIMIR_SUPABASE_SIMILARITY_THRESHOLD=0.2
MIMIR_SUPABASE_MATCH_COUNT=10
MIMIR_SUPABASE_BM25_MATCH_COUNT=10
MIMIR_SUPABASE_ENABLE_HYBRID_SEARCH=true

# GitHub Ingestion Configuration
MIMIR_GITHUB_URL=https://github.com/your-org/your-repo
MIMIR_GITHUB_DIRECTORY=content/docs
MIMIR_GITHUB_BRANCH=main
MIMIR_GITHUB_TOKEN=ghp_your_pat_here
MIMIR_GITHUB_OUTPUT_DIR=./tmp/github-cache

# Documentation Links Configuration
MIMIR_DOCS_BASE_URL=https://your-domain.com/
MIMIR_DOCS_CONTENT_PATH=content/docs

# LLM - Embedding Provider Configuration
# Supported providers: openai, google, anthropic, mistral
MIMIR_LLM_EMBEDDING_PROVIDER=openai
MIMIR_LLM_EMBEDDING_MODEL=text-embedding-3-large
MIMIR_LLM_EMBEDDING_API_KEY=your_embedding_api_key
MIMIR_LLM_EMBEDDING_BASE_URL=

# LLM - Embedding Rate Limits (optional)
MIMIR_LLM_EMBEDDING_LIMITS_BATCH_SIZE=100
MIMIR_LLM_EMBEDDING_LIMITS_CONCURRENCY=4
MIMIR_LLM_EMBEDDING_LIMITS_MAX_REQUESTS_PER_MINUTE=1500
MIMIR_LLM_EMBEDDING_LIMITS_MAX_TOKENS_PER_MINUTE=6250000
MIMIR_LLM_EMBEDDING_LIMITS_RETRIES=6

# LLM - Chat Provider Configuration
# Supported providers: openai, google, anthropic, mistral
MIMIR_LLM_CHAT_PROVIDER=openai
MIMIR_LLM_CHAT_MODEL=gpt-4o-mini
MIMIR_LLM_CHAT_API_KEY=your_chat_api_key
MIMIR_LLM_CHAT_BASE_URL=
MIMIR_LLM_CHAT_TEMPERATURE=0
MIMIR_LLM_CHAT_MAX_OUTPUT_TOKENS=1500

# LLM - Chat Rate Limits (optional)
MIMIR_LLM_CHAT_LIMITS_CONCURRENCY=3
MIMIR_LLM_CHAT_LIMITS_MAX_REQUESTS_PER_MINUTE=500
MIMIR_LLM_CHAT_LIMITS_MAX_TOKENS_PER_MINUTE=90000
MIMIR_LLM_CHAT_LIMITS_RETRIES=5

# Optional Runtime Helpers
PORT=3000
